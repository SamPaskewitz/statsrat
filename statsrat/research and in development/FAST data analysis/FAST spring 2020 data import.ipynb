{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsrat as sr\n",
    "import edit_distance\n",
    "from statsrat import rw\n",
    "from statsrat.expr.predef.cat import fast\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from Levenshtein import distance\n",
    "from read_fast_surveys import promis_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time limit for model fitting (in old R code was Inf, but is 10 by default in current code).\n",
    "max_time = 10\n",
    "\n",
    "# Define learning model.\n",
    "model = rw.model(name = 'CompAct_eta0',\n",
    "                 fbase = rw.fbase.elem,\n",
    "                 fweight = rw.fweight.from_aux_norm,\n",
    "                 lrate = rw.lrate.from_aux_norm,\n",
    "                 drate = rw.drate.zero,\n",
    "                 aux = rw.aux.gradcomp_eta0)\n",
    "\n",
    "# Should we use MLE or the EM algorithm to fit the model, or not fit the model at all?\n",
    "#fit_fun = None # don't fit the model\n",
    "#fit_fun = lambda ds: sr.fit_indv(model, ds, tau = None, max_time = max_time)\n",
    "fit_fun = lambda ds: sr.fit_em(model, ds, max_em_iter = 3, max_time = max_time)\n",
    "\n",
    "# Use Levenstein distance (for consistency with R script); otherwise use ratio.\n",
    "use_distance = True\n",
    "\n",
    "# Should processed data be exported?\n",
    "export_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong number of trials for file fast_data_spring/learning/20_spring_faces_2020_Jan_28_1526.csv\n",
      "trials found: 194\n",
      "trials expected: 204\n",
      "Usecols do not match columns, columns expected but not found: ['trial_resp.keys', 'cue1', 'test_resp.keys', 'cue2']\n",
      "Usecols do not match columns, columns expected but not found: ['test_resp.keys']\n",
      "Usecols do not match columns, columns expected but not found: ['trial_resp.keys', 'cue1', 'test_resp.keys', 'cue2']\n",
      "Usecols do not match columns, columns expected but not found: ['test_resp.keys']\n",
      "Usecols do not match columns, columns expected but not found: ['trial_resp.keys', 'cue1', 'test_resp.keys', 'cue2']\n",
      "Usecols do not match columns, columns expected but not found: ['trial_resp.keys', 'cue1', 'test_resp.keys', 'cue2']\n",
      "Usecols do not match columns, columns expected but not found: ['trial_resp.keys', 'cue1', 'test_resp.keys', 'cue2']\n",
      "Usecols do not match columns, columns expected but not found: ['trial_resp.keys', 'cue1', 'test_resp.keys', 'cue2']\n",
      "Usecols do not match columns, columns expected but not found: ['trial_resp.keys', 'cue1', 'test_resp.keys', 'cue2']\n",
      "Usecols do not match columns, columns expected but not found: ['test_resp.keys']\n",
      "Usecols do not match columns, columns expected but not found: ['trial_resp.keys', 'cue1', 'test_resp.keys', 'cue2']\n",
      "Usecols do not match columns, columns expected but not found: ['trial_resp.keys', 'cue1', 'test_resp.keys', 'cue2']\n",
      "Usecols do not match columns, columns expected but not found: ['trial_resp.keys', 'cue1', 'test_resp.keys', 'cue2']\n",
      "The following files could not be read by Pandas:\n",
      "fast_data_spring/learning/20_spring_faces_2020_Jan_28_1526.csv\n",
      "fast_data_spring/learning/173_spring_faces_2020_Feb_27_0926.csv\n",
      "fast_data_spring/learning/165_spring_faces_2020_Feb_25_1140.csv\n",
      "fast_data_spring/learning/11_spring_faces_2020_Jan_28_1116.csv\n",
      "fast_data_spring/learning/41_spring_faces_2020_Jan_30_1316.csv\n",
      "fast_data_spring/learning/74_spring_faces_2020_Feb_06_0857.csv\n",
      "fast_data_spring/learning/143_spring_faces_2020_Feb_20_0859.csv\n",
      "fast_data_spring/learning/12_spring_faces_2020_Jan_28_1126.csv\n",
      "fast_data_spring/learning/113_spring_faces_2020_Feb_11_1523.csv\n",
      "fast_data_spring/learning/162_spring_faces_2020_Feb_25_0956.csv\n",
      "fast_data_spring/learning/16_spring_faces_2020_Jan_28_1449.csv\n",
      "fast_data_spring/learning/171_spring_faces_2020_Feb_25_1527.csv\n",
      "fast_data_spring/learning/57_spring_faces_2020_Feb_04_1029.csv\n",
      "fast_data_spring/learning/164_spring_faces_2020_Feb_25_1115.csv\n",
      "          schedule  tutorial_0a_last8_pct_correct  \\\n",
      "ident                                               \n",
      "0222rehom   design                          100.0   \n",
      "0111gariv   design                          100.0   \n",
      "0128meher   design                          100.0   \n",
      "0410legra   design                           87.5   \n",
      "0510shfai   design                          100.0   \n",
      "...            ...                            ...   \n",
      "0227macou   design                          100.0   \n",
      "1121romou   design                          100.0   \n",
      "0402jeeli   design                          100.0   \n",
      "0810tatak   design                          100.0   \n",
      "1216vabou   design                           87.5   \n",
      "\n",
      "           tutorial_0b_last8_pct_correct  tutorial_0c_last8_pct_correct  \\\n",
      "ident                                                                     \n",
      "0222rehom                          100.0                          100.0   \n",
      "0111gariv                           87.5                          100.0   \n",
      "0128meher                          100.0                          100.0   \n",
      "0410legra                          100.0                          100.0   \n",
      "0510shfai                          100.0                          100.0   \n",
      "...                                  ...                            ...   \n",
      "0227macou                          100.0                          100.0   \n",
      "1121romou                          100.0                          100.0   \n",
      "0402jeeli                          100.0                          100.0   \n",
      "0810tatak                          100.0                           87.5   \n",
      "1216vabou                          100.0                          100.0   \n",
      "\n",
      "           training_last8_pct_correct  transfer_last8_pct_correct  rel_irl  \\\n",
      "ident                                                                        \n",
      "0222rehom                       100.0                       100.0     0.75   \n",
      "0111gariv                        87.5                       100.0     0.75   \n",
      "0128meher                       100.0                        87.5     1.00   \n",
      "0410legra                       100.0                        75.0     0.25   \n",
      "0510shfai                       100.0                       100.0     0.75   \n",
      "...                               ...                         ...      ...   \n",
      "0227macou                       100.0                       100.0     1.00   \n",
      "1121romou                       100.0                       100.0    -1.00   \n",
      "0402jeeli                        75.0                        87.5     0.25   \n",
      "0810tatak                        75.0                        75.0     0.00   \n",
      "1216vabou                        62.5                        87.5    -0.25   \n",
      "\n",
      "           threat_benign_os  threat_benign_brel  threat_benign_trel  \n",
      "ident                                                                \n",
      "0222rehom               0.5                -0.5                 1.0  \n",
      "0111gariv               0.5                -0.5                 1.0  \n",
      "0128meher               1.0                -1.0                 1.0  \n",
      "0410legra               1.0                 0.0                 0.5  \n",
      "0510shfai              -0.5                -0.5                 1.0  \n",
      "...                     ...                 ...                 ...  \n",
      "0227macou               0.5                -1.0                 1.0  \n",
      "1121romou               0.5                 1.0                -1.0  \n",
      "0402jeeli               0.0                 0.0                 0.5  \n",
      "0810tatak               0.5                -0.5                -0.5  \n",
      "1216vabou              -1.0                 1.0                 0.5  \n",
      "\n",
      "[153 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "(ds_spring2020, summary_spring2020) = fast.read_csv(path = 'fast_data_spring/learning',\n",
    "                                                    x_col = ['cue1', 'cue2'],\n",
    "                                                    resp_col = ['trial_resp.keys', 'test_resp.keys'],\n",
    "                                                    resp_map = {'h' : 'cati', 'g' : 'catii', 'c' : 'cat1', 'm' : 'cat2', 's' : 'cat3', 'r' : 'cat4'},\n",
    "                                                    ident_col = 'sonaID',\n",
    "                                                    #conf_col = 'conf_rating.response',\n",
    "                                                    n_final = 8)\n",
    "\n",
    "\n",
    "print(summary_spring2020)\n",
    "# I have spot-checked the OAT scores computed by the R and Python scripts, and they match up.\n",
    "# However, I'm going to try analyzing the data without the confidence ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** import survey data ****\n",
    "df_surveys = pd.read_csv('fast_data_spring/survey/JonesSec9.csv').dropna()\n",
    "df_surveys.rename(columns = {'IDCode': 'ident',\n",
    "                   'mjon1': 'anx1', # In the past 7 days...I felt fearful\n",
    "                   'mjon2': 'anx2', # In the past 7 days...I found it hard to focus on anything other than my anxiety\n",
    "                   'mjon3': 'anx3', # In the past 7 days...My worries overwhelmed me\n",
    "                   'mjon4': 'anx4', # In the past 7 days...I felt uneasy\n",
    "                   'mjon5': 'anx5', # In the past 7 days...I felt nervous\n",
    "                   'mjon6': 'anx6', # In the past 7 days...I felt like I needed help for my anxiety\n",
    "                   'mjon7': 'anx7', # In the past 7 days...I felt anxious\n",
    "                   'mjon8': 'anx8', # In the past 7 days...I felt tense\n",
    "                   'mjon9': 'ang1', # In the past 7 days...I was irritated more than people knew\n",
    "                   'mjon10': 'ang2', # In the past 7 days...I felt angry\n",
    "                   'mjon11': 'ang3', # In the past 7 days...I felt like I was ready to explode\n",
    "                   'mjon12': 'ang4', # In the past 7 days...I was grouchy\n",
    "                   'mjon13': 'ang5', # In the past 7 days...I felt annoyed\n",
    "                   'mjon14': 'dep1', # In the past 7 days...I felt worthless\n",
    "                   'mjon15': 'dep2', # In the past 7 days...I felt that I had nothing to look forward to\n",
    "                   'mjon16': 'dep3', # In the past 7 days...I felt helpless\n",
    "                   'mjon17': 'dep4', # In the past 7 days...I felt sad\n",
    "                   'mjon18': 'dep5', # In the past 7 days...I felt like a failure\n",
    "                   'mjon19': 'dep6', # In the past 7 days...I felt depressed\n",
    "                   'mjon20': 'dep7', # In the past 7 days...I felt unhappy\n",
    "                   'mjon21': 'dep8', # In the past 7 days...I felt hopeless\n",
    "                   'mjon22': 'pos1', # In the past 7 days...I felt cheerful\n",
    "                   'mjon23': 'pos2', # In the past 7 days...I felt attentive\n",
    "                   'mjon24': 'pos3', # In the past 7 days...I felt delighted\n",
    "                   'mjon25': 'pos4', # In the past 7 days...I felt happy\n",
    "                   'mjon26': 'pos5', # In the past 7 days...I felt joyful\n",
    "                   'mjon27': 'pos6', # In the past 7 days...I felt enthusiastic\n",
    "                   'mjon28': 'pos7', # In the past 7 days...I felt determined\n",
    "                   'mjon29': 'pos8', # In the past 7 days...I felt interested\n",
    "                   'mjon30': 'pos9', # In the past 7 days...I was thinking creatively\n",
    "                   'mjon31': 'pos10', # In the past 7 days...I liked myself\n",
    "                   'mjon32': 'pos11', # In the past 7 days...I felt peaceful\n",
    "                   'mjon33': 'pos12', # In the past 7 days...I felt good-natured\n",
    "                   'mjon34': 'pos13', # In the past 7 days...I felt useful\n",
    "                   'mjon35': 'pos14', # In the past 7 days...I felt understood\n",
    "                   'mjon36': 'pos15'}, # In the past 7 days...I felt content\n",
    "                  inplace = True)\n",
    "df_surveys['ident'] = df_surveys['ident'].str.lower()\n",
    "df_surveys.set_index('ident', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** perform PROMIS calculations ****\n",
    "\n",
    "col_names = []\n",
    "for i in range(8):\n",
    "    col_names += ['anx' + str(i + 1)]\n",
    "df_surveys['promis_anx_sum'] = df_surveys[col_names].sum(axis = 1)\n",
    "df_surveys['promis_anx_std'] = df_surveys[col_names].std(axis = 1)\n",
    "df_surveys['promis_anx'] = promis_lookup(df_surveys['promis_anx_sum'], 'anx')\n",
    "\n",
    "col_names = []\n",
    "for i in range(5):\n",
    "    col_names += ['ang' + str(i + 1)]\n",
    "df_surveys['promis_ang_sum'] = df_surveys[col_names].sum(axis = 1, skipna = False)\n",
    "df_surveys['promis_ang_std'] = df_surveys[col_names].std(axis = 1, skipna = False)\n",
    "df_surveys['promis_ang'] = promis_lookup(df_surveys['promis_ang_sum'], 'ang')\n",
    "\n",
    "col_names = []\n",
    "for i in range(8):\n",
    "    col_names += ['dep' + str(i + 1)]\n",
    "df_surveys['promis_dep_sum'] = df_surveys[col_names].sum(axis = 1, skipna = False)\n",
    "df_surveys['promis_dep_std'] = df_surveys[col_names].std(axis = 1, skipna = False)\n",
    "df_surveys['promis_dep'] = promis_lookup(df_surveys['promis_dep_sum'], 'dep8b')\n",
    "\n",
    "col_names = []\n",
    "for i in range(15):\n",
    "    col_names += ['pos' + str(i + 1)]\n",
    "df_surveys['promis_pos_sum'] = df_surveys[col_names].sum(axis = 1, skipna = False)\n",
    "df_surveys['promis_pos_std'] = df_surveys[col_names].std(axis = 1, skipna = False)\n",
    "df_surveys['promis_pos'] = promis_lookup(df_surveys['promis_pos_sum'], 'pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0128meher\n",
      "0823beher\n",
      "\n",
      "\n",
      "0920mafra\n",
      "0926mepra\n",
      "\n",
      "\n",
      "0414mitrh\n",
      "0414mithu\n",
      "\n",
      "\n",
      "0709kabis\n",
      "0306kabis\n",
      "\n",
      "\n",
      "0422faeas\n",
      "0425kawas\n",
      "\n",
      "\n",
      "0316duher\n",
      "0329doher\n",
      "\n",
      "\n",
      "1115susai\n",
      "1115sasai\n",
      "\n",
      "\n",
      "0331jamur\n",
      "0331jamurrow\n",
      "\n",
      "\n",
      "0602shpas\n",
      "0502shpal\n",
      "\n",
      "\n",
      "0628elnot\n",
      "0620junot\n",
      "\n",
      "\n",
      "0319jebis\n",
      "0319jevai\n",
      "\n",
      "\n",
      "0126krchy\n",
      "0426krdch\n",
      "\n",
      "\n",
      "0818karoc\n",
      "0718laroc\n",
      "\n",
      "\n",
      "1101livis\n",
      "1105mavis\n",
      "\n",
      "\n",
      "1118cacat\n",
      "1118cadocat\n",
      "\n",
      "\n",
      "0702digol\n",
      "0708cagol\n",
      "\n",
      "\n",
      "0522kafhs\n",
      "0529kacas\n",
      "\n",
      "\n",
      "1116lotor\n",
      "1113sonor\n",
      "\n",
      "\n",
      "0501trbou\n",
      "0101crmou\n",
      "\n",
      "\n",
      "1030masky\n",
      "1030malan\n",
      "\n",
      "\n",
      "1216vabou\n",
      "0116mabou\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# **** drop people not found in FAST data, and fix IDs ****\n",
    "\n",
    "# https://www.datacamp.com/community/tutorials/fuzzy-string-python\n",
    "# https://pypi.org/project/fuzzywuzzy/\n",
    "# https://pypi.org/project/python-Levenshtein/#documentation\n",
    "\n",
    "# Loop through FAST data.\n",
    "survey_ident = df_surveys.index.values # list of IDs found in the survey data\n",
    "new_ident = []\n",
    "for ident in summary_spring2020.index:\n",
    "    \n",
    "    if use_distance:\n",
    "        # Use Levenstein distance (for consistency with the R script).\n",
    "        dist = []\n",
    "        for sident in survey_ident:\n",
    "            dist += [distance(ident, sident)]\n",
    "        best_match = survey_ident[np.argmin(dist)]\n",
    "        min_dist = np.min(dist)\n",
    "        close_enough = min_dist <= 3\n",
    "        exact_match = min_dist == 0\n",
    "    else:\n",
    "        # Use ratio.\n",
    "        best_match, match_pct = process.extractOne(ident, survey_ident, scorer = fuzz.ratio)\n",
    "        close_enough = match_pct >= 70\n",
    "        exact_match = match_pct == 100\n",
    "    \n",
    "    if close_enough:\n",
    "        if not exact_match:\n",
    "            print(ident)\n",
    "            print(best_match)\n",
    "            print('\\n')\n",
    "        new_ident += [best_match]\n",
    "    else:\n",
    "        # Only keep people whose survey data can be found.\n",
    "        summary_spring2020.drop(index = ident, inplace = True)\n",
    "        ds_spring2020 = ds_spring2020.drop_sel(ident = [ident])\n",
    "summary_spring2020['new_ident'] = new_ident\n",
    "old_ident = summary_spring2020.index.values\n",
    "summary_spring2020.set_index('new_ident', inplace = True)\n",
    "\n",
    "# Concatenate data frames.\n",
    "summary_spring2020 = pd.concat([summary_spring2020, df_surveys.loc[new_ident]], axis = 1)\n",
    "summary_spring2020['ident'] = old_ident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial estimation with uniform priors\n",
      "Fitting 1 of 127 (0.8%)\n",
      "Fitting 2 of 127 (1.6%)\n",
      "Fitting 3 of 127 (2.4%)\n",
      "Fitting 4 of 127 (3.1%)\n",
      "Fitting 5 of 127 (3.9%)\n",
      "Fitting 6 of 127 (4.7%)\n",
      "Fitting 7 of 127 (5.5%)\n",
      "Fitting 8 of 127 (6.3%)\n",
      "Fitting 9 of 127 (7.1%)\n",
      "Fitting 10 of 127 (7.9%)\n",
      "Fitting 11 of 127 (8.7%)\n",
      "Fitting 12 of 127 (9.4%)\n",
      "Fitting 13 of 127 (10.2%)\n",
      "Fitting 14 of 127 (11.0%)\n",
      "Fitting 15 of 127 (11.8%)\n",
      "Fitting 16 of 127 (12.6%)\n",
      "Fitting 17 of 127 (13.4%)\n",
      "Fitting 18 of 127 (14.2%)\n",
      "Fitting 19 of 127 (15.0%)\n",
      "Fitting 20 of 127 (15.7%)\n",
      "Fitting 21 of 127 (16.5%)\n",
      "Fitting 22 of 127 (17.3%)\n",
      "Fitting 23 of 127 (18.1%)\n",
      "Fitting 24 of 127 (18.9%)\n",
      "Fitting 25 of 127 (19.7%)\n",
      "Fitting 26 of 127 (20.5%)\n",
      "Fitting 27 of 127 (21.3%)\n",
      "Fitting 28 of 127 (22.0%)\n",
      "Fitting 29 of 127 (22.8%)\n",
      "Fitting 30 of 127 (23.6%)\n",
      "Fitting 31 of 127 (24.4%)\n",
      "Fitting 32 of 127 (25.2%)\n",
      "Fitting 33 of 127 (26.0%)\n",
      "Fitting 34 of 127 (26.8%)\n"
     ]
    }
   ],
   "source": [
    "if not fit_fun is None:\n",
    "    # Fit model.\n",
    "    df_model = fit_fun(ds_spring2020)\n",
    "    df_model['new_ident'] = new_ident\n",
    "    df_model.set_index('new_ident', inplace = True)\n",
    "    # Concatenate data frames.\n",
    "    summary_spring2020 = pd.concat([summary_spring2020, df_model], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARISON OF LOG-LIKELIHOOD VALUES BETWEEN THE PYTHON AND R CODE\n",
    "# R log-likelihood values\n",
    "# 1116nawes: -117.40835\n",
    "# 1014cynis: -79.11026\n",
    "# 0630mypou: -41.63949\n",
    "# 1216edasf: -65.33993\n",
    "\n",
    "#print(sr.log_lik(model, ds_spring2020.loc[{'ident': '1116nawes'}], par_val = [0.3079861, 0.10629251, 0.04122127, 10.0000000, 2.1102876]))\n",
    "#print(sr.log_lik(model, ds_spring2020.loc[{'ident': '1014cynis'}], par_val = [4.0032015, 0.21623505, 1.99000000, 10.0000000, 2.9885900]))\n",
    "#print(sr.log_lik(model, ds_spring2020.loc[{'ident': '0630mypou'}], par_val = [1.2883276, 0.16728406, 1.96853767, 1.0716446, 7.4701937]))\n",
    "#print(sr.log_lik(model, ds_spring2020.loc[{'ident': '1216edasf'}], par_val = [0.9602774, 0.17666184, 1.73290646, 1.2863178, 4.0602626]))\n",
    "\n",
    "# It looks the log-likelihood values produced by the R and Python versions are close, but not quite identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add performance criterion.\n",
    "# >= 75% on all stages (lumping all parts of stage 0 together as one stage) is the criterion for good performance that we used to analyze the Spring 2020 data. \n",
    "summary_spring2020['good_perf'] = (summary_spring2020['tutorial_0c_last8_pct_correct'] >= 75)&(summary_spring2020['training_last8_pct_correct'] >= 75)&(summary_spring2020['transfer_last8_pct_correct'] >= 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_data:\n",
    "    # ***** EXPORT PROCESSED DATA *****\n",
    "    summary_spring2020.to_csv('summary_spring2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
