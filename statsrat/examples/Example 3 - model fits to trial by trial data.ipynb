{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsrat as sr\n",
    "from statsrat import rw\n",
    "from statsrat import expr\n",
    "\n",
    "# IMPORTANT NOTE: the \"data\" in this example are synthetic, i.e. generated by simulation rather than from\n",
    "# actual human participants.  This is to avoid any worries privacy issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MODELS\n",
    "\n",
    "# The derived attention model from Le Pelley, Mitchell, Beesley, George and Wills (2016).\n",
    "drva = rw.model(name = 'drva',\n",
    "                pred = rw.pred.identity,\n",
    "                fbase = rw.fbase.elem,\n",
    "                fweight = rw.fweight.none,\n",
    "                lrate = rw.lrate.from_aux_feature,\n",
    "                drate = rw.drate.zero,\n",
    "                aux = rw.aux.drva)\n",
    "\n",
    "# CompAct (with only elemental features); Model 4 from Paskewitz and Jones (2020).\n",
    "CompAct = rw.model(name = 'CompAct',\n",
    "                   pred = rw.pred.identity,\n",
    "                   fbase = rw.fbase.elem,\n",
    "                   fweight = rw.fweight.from_aux_norm,\n",
    "                   lrate = rw.lrate.from_aux_norm,\n",
    "                   drate = rw.drate.zero,\n",
    "                   aux = rw.aux.gradcomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE EXPERIMENT\n",
    "\n",
    "# Loosely based on Le Pelley and McLaren 2003 (learned predictiveness)\n",
    "\n",
    "# ADD COMMENTS TO GIVE MORE DETAIL\n",
    "design = expr.schedule(resp_type = 'choice',\n",
    "                      stages = {'training': expr.stage(\n",
    "                                        x_pn = [['a', 'v'], ['b', 'v'], ['a', 'w'], ['b', 'w'], ['c', 'x'], ['d', 'x'], ['c', 'y'], ['d', 'y']],\n",
    "                                        y = 4*[['cat1'], ['cat2']],\n",
    "                                        y_psb = ['cat1', 'cat2'],\n",
    "                                        n_rep = 14),\n",
    "                                  'transfer': expr.stage(\n",
    "                                        x_pn = [['a', 'x'], ['b', 'y'], ['c', 'v'], ['d', 'w'], ['e', 'f'], ['g', 'h'], ['i', 'j'], ['k', 'l']],\n",
    "                                        y = 4*[['cat3'], ['cat4']],\n",
    "                                        y_psb = ['cat3', 'cat4'],\n",
    "                                        n_rep = 4),\n",
    "                                  'test': expr.stage(\n",
    "                                        x_pn = [['a', 'c'], ['b', 'd'], ['v', 'x'], ['w', 'y'], ['e', 'h'], ['f', 'g'], ['i', 'j'], ['k', 'l']],\n",
    "                                        y_psb = ['cat3', 'cat4'],\n",
    "                                        lrn = False,\n",
    "                                        n_rep = 1)})\n",
    "\n",
    "rel_irl = expr.oat(schedule_pos = ['design'],\n",
    "                   behav_score_pos = expr.behav_score(stage = 'test',\n",
    "                                                      trial_pos = ['a.c -> nothing', 'b.d -> nothing'],\n",
    "                                                      trial_neg = ['v.x -> nothing', 'w.y -> nothing'],\n",
    "                                                      resp_pos = ['cat3', 'cat4'],\n",
    "                                                      resp_neg = ['cat3', 'cat4']))\n",
    "\n",
    "lrn_pred = expr.experiment(schedules = {'design': design},\n",
    "                           oats = {'rel_irl': rel_irl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method read_csv in module statsrat.expr.experiment:\n",
      "\n",
      "read_csv(path, x_col, resp_col, resp_map, ident_col=None, conf_col=None, schedule=None, other_info=None, header='infer', n_final=8) method of statsrat.expr.experiment.experiment instance\n",
      "    Import empirical data from .csv files.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path: str\n",
      "        Path to the .csv files.\n",
      "    x_col: list\n",
      "        Names of columns (strings) indicating cues (stimulus\n",
      "        attributes, i.e. columns of 'x').\n",
      "    resp_col: list\n",
      "        Names of columns (strings) indicating responses.\n",
      "    resp_map: dict\n",
      "        Maps response names in the raw data to response names in the\n",
      "        schedule definition.\n",
      "    ident_col: str or None, optional\n",
      "        If string, name of column indicating individual identifier\n",
      "        (the 'ident' variable).  If None, then file names are used\n",
      "        as 'ident'.  Defaults to None.\n",
      "    conf_col: str or None, optional\n",
      "        Name of the column indicating confidence responses (i.e.\n",
      "        a measure of confidence following choices, typically\n",
      "        obtained in the test stages of human classification tasks).\n",
      "        Defaults to None (suitable for data without confidence responses).\n",
      "    schedule: str, optional\n",
      "        Name of the schedule from which to make trials.  By default\n",
      "        selects the first schedule in the experiment object's\n",
      "        definition.\n",
      "    other_info: dict or None, optional\n",
      "        Specifies other information (e.g. demographics) to be imported.\n",
      "        Dictionary keys are variable names (e.g. 'sex', 'age'), while the\n",
      "        values give the corresponding row index (e.g. a question such as \n",
      "        'What is your age?') and column name as a tuple.  Defaults to None\n",
      "        (do not import any additional data).\n",
      "    header: int or list of int, default ‘infer’\n",
      "        Passed to pandas.read_csv.  Row number(s) to use as the column names,\n",
      "        and the start of the data.\n",
      "    n_final: int, optional\n",
      "        Number of trials at end of each stage to use for calculating percent correct\n",
      "        choices.  For example, set n_final = 10 to compute percent correct choices\n",
      "        using the last 10 trials of each stage.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    ds : dataset (xarray)\n",
      "        Contains time step level data (stimuli, outcomes, behavior,\n",
      "        possible outcomes etc.).\n",
      "    summary : dataframe (pandas)\n",
      "        Each row corresponds to a participant.  Contains proportion of\n",
      "        correct responses in each non-test stage, plus OAT scores.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    To avoid confusion, data from different schedules (e.g. different experimental\n",
      "    groups) should be kept in separate directories.\n",
      "    \n",
      "    It is assumed that any numeric particpant identifiers ('ident') are\n",
      "    integers rather than floats.\n",
      "    \n",
      "    The 'correct' variable encodes whether participant behavior ('b') matched\n",
      "    the outcome ('y').  It is only really valid for category learning and similar\n",
      "    experiments, and does not mean anything for stages without feedback (i.e. test stages).\n",
      "    \n",
      "    Participant IDs (called 'ident') should be unique.  Any duplicates will be modified by\n",
      "    adding '-1', '-2', '-3' etc. (respectively for the second, third, fourth etc. instance\n",
      "    of the ID) to the end of the ID string.\n",
      "    \n",
      "    Current Limitations:\n",
      "    \n",
      "    For now, I assume that each time step represents a trial (i.e. iti = 0).\n",
      "    \n",
      "    I also assume that all 'x_names' in the Python schedule object are lower case.\n",
      "    \n",
      "    I also assume that each stage has at most one trial type for any set of punctate cues.\n",
      "    \n",
      "    I also assume that the Python schedule object has exactly the right number of trials.\n",
      "    \n",
      "    Currently, the 'time' (real world time) coordinate is only a copy of 't' (the time step\n",
      "    number).  This represents the assumption that there are no delays between stages of the\n",
      "    experiment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Documentation on the read_csv method (used to import data)\n",
    "help(lrn_pred.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT THE (SYNTHETIC) DATA\n",
    "\n",
    "(ds, summary) = lrn_pred.read_csv(path = 'data/',\n",
    "                                  x_col = ['left_stim', 'right_stim'],\n",
    "                                  resp_col = ['key_press'],\n",
    "                                  resp_map = {'a': 'cat1', 's': 'cat2', 'd': 'cat3', 'f': 'cat4'},\n",
    "                                  ident_col = 'subject_id',\n",
    "                                  conf_col = 'confidence_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:     (ident: 10, t: 152, x_name: 16, y_name: 4)\n",
      "Coordinates:\n",
      "  * ident       (ident) <U4 'sim7' 'sim6' 'sim0' 'sim1' ... 'sim2' 'sim9' 'sim8'\n",
      "  * t           (t) int64 0 1 2 3 4 5 6 7 8 ... 144 145 146 147 148 149 150 151\n",
      "    t_name      (t) <U4 'main' 'main' 'main' 'main' ... 'main' 'main' 'main'\n",
      "    ex          (ident, t) <U3 'b.v' 'd.x' 'c.y' 'b.w' ... 'k.l' 'v.x' 'b.d'\n",
      "    trial       (t) int64 0 1 2 3 4 5 6 7 8 ... 144 145 146 147 148 149 150 151\n",
      "    trial_name  (ident, t) <U14 'b.v -> cat2' 'd.x -> cat2' ... 'b.d -> nothing'\n",
      "    stage       (t) int64 0 0 0 0 0 0 0 0 0 0 0 ... 8 8 16 16 16 16 16 16 16 16\n",
      "    stage_name  (t) <U8 'training' 'training' 'training' ... 'test' 'test'\n",
      "  * x_name      (x_name) <U1 'a' 'b' 'c' 'd' 'e' 'f' ... 'k' 'l' 'v' 'w' 'x' 'y'\n",
      "  * y_name      (y_name) <U4 'cat1' 'cat2' 'cat3' 'cat4'\n",
      "    time        (t) int64 0 1 2 3 4 5 6 7 8 ... 144 145 146 147 148 149 150 151\n",
      "Data variables:\n",
      "    x           (ident, t, x_name) float64 0.0 1.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
      "    y           (ident, t, y_name) float64 0.0 1.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
      "    y_psb       (ident, t, y_name) float64 1.0 1.0 0.0 0.0 ... 0.0 0.0 1.0 1.0\n",
      "    y_lrn       (ident, t, y_name) float64 1.0 1.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
      "    b           (ident, t, y_name) int64 0 1 0 0 0 1 0 0 1 ... 1 0 0 1 0 0 0 0 1\n",
      "    conf        (ident, t) float64 0.0 0.0 0.0 0.0 0.0 ... 12.0 10.0 8.0 12.0\n",
      "    correct     (ident, t) bool True True True True ... False False False False\n",
      "Attributes:\n",
      "    x_ex:              a    b    c    d    e    f    g    h    i    j    k   ...\n",
      "    ex_names:   ['w.y' 'v.x' 'k.l' 'i.j' 'g.h' 'f.g' 'e.h' 'e.f' 'd.y' 'd.x' ...\n",
      "    resp_type:  choice\n"
     ]
    }
   ],
   "source": [
    "# View trial by trial dataset\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       training_last8_pct_correct  transfer_last8_pct_correct  rel_irl\n",
      "ident                                                                 \n",
      "sim7                        100.0                       100.0      7.5\n",
      "sim6                         50.0                        37.5      5.5\n",
      "sim0                        100.0                       100.0      2.0\n",
      "sim1                        100.0                        87.5      1.0\n",
      "sim4                         75.0                       100.0      2.0\n",
      "sim5                        100.0                       100.0     11.5\n",
      "sim3                         37.5                        87.5      1.0\n",
      "sim2                         87.5                       100.0      2.5\n",
      "sim9                        100.0                       100.0      3.0\n",
      "sim8                        100.0                       100.0      4.0\n"
     ]
    }
   ],
   "source": [
    "# View summary dataframe\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample a subset of the data for compare optimization algorithms etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST MODEL (**MODEL NAME**)\n",
    "\n",
    "# Test different optimization algorithms (subset of data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine how long the optimization algorithm needs to run (subset of data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data (full dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECOND MODEL (**MODEL NAME**)\n",
    "\n",
    "# Test different optimization algorithms (subset of data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine how long the optimization algorithm needs to run (subset of data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data (full dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare AIC (Akaike Information Criterion) values\n",
    "# These are based on a log-likelihood but penalize the number of free parameters\n",
    "# Higher is better\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
